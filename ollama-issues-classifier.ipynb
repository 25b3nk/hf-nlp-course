{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/csbenk/ollama-issues-classifier?scriptVersionId=220218834\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Setup","metadata":{}},{"cell_type":"code","source":"!pip install datasets evaluate transformers[sentencepiece]\n!apt install git-lfs","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!git config --global user.email \"csbhaskar95@gmail.com\"\n!git config --global user.name \"25b3nk\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T06:07:21.596556Z","iopub.execute_input":"2025-02-01T06:07:21.59698Z","iopub.status.idle":"2025-02-01T06:07:21.874805Z","shell.execute_reply.started":"2025-02-01T06:07:21.596946Z","shell.execute_reply":"2025-02-01T06:07:21.8737Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T06:07:24.464071Z","iopub.execute_input":"2025-02-01T06:07:24.464412Z","iopub.status.idle":"2025-02-01T06:07:24.879738Z","shell.execute_reply.started":"2025-02-01T06:07:24.464384Z","shell.execute_reply":"2025-02-01T06:07:24.878834Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32766e321f934be3bce650dd2948a310"}},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"# Load dataset and filter the data to get ready for training","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\n\nremote_dataset = load_dataset(\"25b3nk/ollama-github-issues\")\nremote_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T06:08:30.820464Z","iopub.execute_input":"2025-02-01T06:08:30.820942Z","iopub.status.idle":"2025-02-01T06:08:34.631372Z","shell.execute_reply.started":"2025-02-01T06:08:30.820903Z","shell.execute_reply":"2025-02-01T06:08:34.630695Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/5.84k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38f2693ed8ea4a3c9ec90c338de3f89c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/6.78M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11073d771f9e440a8020f0506dfc1e4a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/1.82M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e6c05e7bb654a189dcea215048682bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/6860 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec5200e8770543d6b61e5d40bbceefa0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1716 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f9f1f011188444188bb985d5950a2b0"}},"metadata":{}},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['url', 'repository_url', 'labels_url', 'comments_url', 'events_url', 'html_url', 'id', 'node_id', 'number', 'title', 'user', 'labels', 'state', 'locked', 'assignee', 'assignees', 'milestone', 'comments', 'created_at', 'updated_at', 'closed_at', 'author_association', 'sub_issues_summary', 'active_lock_reason', 'draft', 'pull_request', 'body', 'closed_by', 'reactions', 'timeline_url', 'performed_via_github_app', 'state_reason', 'is_pull_request'],\n        num_rows: 6860\n    })\n    test: Dataset({\n        features: ['url', 'repository_url', 'labels_url', 'comments_url', 'events_url', 'html_url', 'id', 'node_id', 'number', 'title', 'user', 'labels', 'state', 'locked', 'assignee', 'assignees', 'milestone', 'comments', 'created_at', 'updated_at', 'closed_at', 'author_association', 'sub_issues_summary', 'active_lock_reason', 'draft', 'pull_request', 'body', 'closed_by', 'reactions', 'timeline_url', 'performed_via_github_app', 'state_reason', 'is_pull_request'],\n        num_rows: 1716\n    })\n})"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"filtered_dataset = remote_dataset.filter(lambda x: x[\"is_pull_request\"] == False).filter(lambda x: x[\"body\"] is not None)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T06:08:45.360838Z","iopub.execute_input":"2025-02-01T06:08:45.361325Z","iopub.status.idle":"2025-02-01T06:08:48.057749Z","shell.execute_reply.started":"2025-02-01T06:08:45.361297Z","shell.execute_reply":"2025-02-01T06:08:48.056888Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/6860 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04f195c951a94a41b465259648f6a117"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/1716 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4fa97b4dc45403d9ede9fb529c3bd93"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/4553 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df9741574fea409185e30863a772a8ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/1168 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed4c6155e1214dbaa545dd3c0fa930a9"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"all_labels = set()\nfor labels in filtered_dataset[\"train\"][\"labels\"]:\n  for label in labels:\n    all_labels.add(label[\"name\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T06:09:25.508222Z","iopub.execute_input":"2025-02-01T06:09:25.508521Z","iopub.status.idle":"2025-02-01T06:09:25.601961Z","shell.execute_reply.started":"2025-02-01T06:09:25.508499Z","shell.execute_reply":"2025-02-01T06:09:25.601294Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"label2id = {label: i for i, label in enumerate(all_labels)}\nid2label = {i: label for i, label in enumerate(all_labels)}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T06:09:31.234355Z","iopub.execute_input":"2025-02-01T06:09:31.234644Z","iopub.status.idle":"2025-02-01T06:09:31.23867Z","shell.execute_reply.started":"2025-02-01T06:09:31.234623Z","shell.execute_reply":"2025-02-01T06:09:31.237809Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import numpy as np\n\ndef encode_labels(example):\n    labels = example['labels']  # Split string into individual labels\n    label_ids = [label2id[label[\"name\"]] for label in labels if label[\"name\"] in label2id]\n\n    # Create a multi-hot vector with the length of all unique labels\n    multi_hot = np.zeros(len(all_labels), dtype=int)\n    multi_hot[label_ids] = 1\n    example['multi_hot_labels'] = multi_hot.tolist()  # Convert back to a list to save in dataset\n    example['label_ids'] = label_ids\n    return example","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T06:09:37.175481Z","iopub.execute_input":"2025-02-01T06:09:37.175847Z","iopub.status.idle":"2025-02-01T06:09:37.181653Z","shell.execute_reply.started":"2025-02-01T06:09:37.175813Z","shell.execute_reply":"2025-02-01T06:09:37.18075Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"encoded_dataset = filtered_dataset.map(encode_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T06:09:44.751796Z","iopub.execute_input":"2025-02-01T06:09:44.752145Z","iopub.status.idle":"2025-02-01T06:09:47.340742Z","shell.execute_reply.started":"2025-02-01T06:09:44.752119Z","shell.execute_reply":"2025-02-01T06:09:47.339883Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/4484 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0f586712b914db893983359f2b0659b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1152 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"690c4bbc0c874edd9070ac36e72f4dc0"}},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"# Tokenize the dataset","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ncheckpoint = \"bert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T06:10:20.798112Z","iopub.execute_input":"2025-02-01T06:10:20.798433Z","iopub.status.idle":"2025-02-01T06:10:28.846987Z","shell.execute_reply.started":"2025-02-01T06:10:20.798404Z","shell.execute_reply":"2025-02-01T06:10:28.846108Z"}},"outputs":[{"name":"stderr","text":"The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"910941585c5647af939ed7f14cfd0885"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a344e5e39feb48fa82b0f84a3b8cf061"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"988286442811486389db7432bb4db38b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4ae433288ad40d198f593228201829b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8033968601f4ec8986b182f09d0cabb"}},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"encoded_dataset[\"train\"].features[\"body\"]\ntokenizer(encoded_dataset[\"train\"][0][\"body\"], truncation=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T06:10:28.848003Z","iopub.execute_input":"2025-02-01T06:10:28.84839Z","iopub.status.idle":"2025-02-01T06:10:28.86146Z","shell.execute_reply.started":"2025-02-01T06:10:28.848367Z","shell.execute_reply":"2025-02-01T06:10:28.86062Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [101, 1045, 4384, 2008, 1996, 19330, 10278, 2050, 2544, 12057, 2004, 8946, 2121, 11661, 2038, 2042, 7172, 2000, 1014, 1012, 1015, 1012, 2654, 1998, 2947, 2323, 2448, 2732, 16044, 2099, 2475, 1998, 19073, 4275, 1011, 1045, 2572, 2145, 2025, 2383, 6735, 2770, 2216, 1010, 19330, 10278, 2050, 2074, 19119, 1012, 1012, 1012, 2572, 1045, 4394, 2242, 1029, 16770, 1024, 1013, 1013, 19351, 8428, 1012, 4012, 1013, 2632, 3501, 12881, 13213, 2629, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"def tokenize_github_issues(examples):\n  return tokenizer(examples[\"body\"], truncation=True, padding=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T06:10:42.059562Z","iopub.execute_input":"2025-02-01T06:10:42.059964Z","iopub.status.idle":"2025-02-01T06:10:42.063857Z","shell.execute_reply.started":"2025-02-01T06:10:42.059929Z","shell.execute_reply":"2025-02-01T06:10:42.063036Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"tokenized_datasets = encoded_dataset.map(tokenize_github_issues, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T06:10:52.33693Z","iopub.execute_input":"2025-02-01T06:10:52.337246Z","iopub.status.idle":"2025-02-01T06:10:57.470389Z","shell.execute_reply.started":"2025-02-01T06:10:52.337219Z","shell.execute_reply":"2025-02-01T06:10:57.469454Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/4484 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30c6689b7ec54929abeb9b525444b82f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1152 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1be68d4563b442dba7789a74848df243"}},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"tokenized_datasets = tokenized_datasets.remove_columns(['url', 'repository_url', 'labels_url', 'comments_url', 'events_url', 'html_url', 'id', 'node_id', 'number', 'title', 'user', 'labels', 'state', 'locked', 'assignee', 'assignees', 'milestone', 'comments', 'created_at', 'updated_at', 'closed_at', 'author_association', 'sub_issues_summary', 'active_lock_reason', 'draft', 'pull_request', 'body', 'closed_by', 'reactions', 'timeline_url', 'performed_via_github_app', 'state_reason', 'is_pull_request'])\ntokenized_datasets = tokenized_datasets.rename_column(\"multi_hot_labels\", \"labels\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T06:11:18.063095Z","iopub.execute_input":"2025-02-01T06:11:18.06342Z","iopub.status.idle":"2025-02-01T06:11:18.085237Z","shell.execute_reply.started":"2025-02-01T06:11:18.063393Z","shell.execute_reply":"2025-02-01T06:11:18.084538Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"tokenized_datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T06:11:25.72113Z","iopub.execute_input":"2025-02-01T06:11:25.721409Z","iopub.status.idle":"2025-02-01T06:11:25.726587Z","shell.execute_reply.started":"2025-02-01T06:11:25.721389Z","shell.execute_reply":"2025-02-01T06:11:25.725667Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['labels', 'label_ids', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 4484\n    })\n    test: Dataset({\n        features: ['labels', 'label_ids', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 1152\n    })\n})"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"import torch\n\ntokenized_datasets.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n# tokenized_datasets = tokenized_datasets.map(lambda x: {'labels': torch.FloatTensor(x['labels'])})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T06:11:34.93794Z","iopub.execute_input":"2025-02-01T06:11:34.938237Z","iopub.status.idle":"2025-02-01T06:11:34.942985Z","shell.execute_reply.started":"2025-02-01T06:11:34.938215Z","shell.execute_reply":"2025-02-01T06:11:34.942121Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"# Setup training params","metadata":{}},{"cell_type":"code","source":"from transformers import DataCollatorWithPadding\n\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T06:12:12.72001Z","iopub.execute_input":"2025-02-01T06:12:12.720573Z","iopub.status.idle":"2025-02-01T06:12:12.72407Z","shell.execute_reply.started":"2025-02-01T06:12:12.720549Z","shell.execute_reply":"2025-02-01T06:12:12.723134Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\ntrain_dataloader = DataLoader(\n    tokenized_datasets[\"train\"], shuffle=True, batch_size=8, collate_fn=data_collator\n)\n\neval_dataloader = DataLoader(\n    tokenized_datasets[\"test\"], batch_size=8, collate_fn=data_collator\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T06:12:15.898475Z","iopub.execute_input":"2025-02-01T06:12:15.89884Z","iopub.status.idle":"2025-02-01T06:12:15.903263Z","shell.execute_reply.started":"2025-02-01T06:12:15.8988Z","shell.execute_reply":"2025-02-01T06:12:15.902371Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\n\nmodel = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=len(all_labels),id2label=id2label, label2id=label2id, problem_type=\"multi_label_classification\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T06:12:29.817189Z","iopub.execute_input":"2025-02-01T06:12:29.817399Z","iopub.status.idle":"2025-02-01T06:12:29.930231Z","shell.execute_reply.started":"2025-02-01T06:12:29.81738Z","shell.execute_reply":"2025-02-01T06:12:29.929627Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"# Testing\nfor batch in train_dataloader:\n  val = {k: v.shape for k, v in batch.items()}\n  print(f\"{val}\")\n  batch['labels'] = batch['labels'].float()\n  outputs = model(**batch)\n  print(outputs.loss, outputs.logits.shape)\n  break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T06:12:44.16032Z","iopub.execute_input":"2025-02-01T06:12:44.160625Z","iopub.status.idle":"2025-02-01T06:12:49.401Z","shell.execute_reply.started":"2025-02-01T06:12:44.160592Z","shell.execute_reply":"2025-02-01T06:12:49.400089Z"}},"outputs":[{"name":"stdout","text":"{'labels': torch.Size([8, 35]), 'input_ids': torch.Size([8, 512]), 'attention_mask': torch.Size([8, 512])}\ntensor(0.7211, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) torch.Size([8, 35])\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"import torch\nfrom transformers import AdamW\nfrom sklearn.metrics import accuracy_score, f1_score\n\nimport os\n\n# Directory to save the checkpoint\ncheckpoint_dir = \"/content/drive/MyDrive/checkpoint_dir\"\nos.makedirs(checkpoint_dir, exist_ok=True)\n\n# Save model, optimizer, and epoch number\ndef save_checkpoint(model, optimizer, epoch, step):\n    model.save_pretrained(checkpoint_dir)\n    tokenizer.save_pretrained(checkpoint_dir)\n    torch.save({\n        'epoch': epoch,\n        'step': step,\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n    }, os.path.join(checkpoint_dir, 'checkpoint.pt'))\n\ndef load_checkpoint(model, optimizer, checkpoint_dir):\n  ck_path = os.path.join(checkpoint_dir, 'checkpoint.pt')\n  if not os.path.exists(ck_path):\n    return model, optimizer, 0, 0\n  checkpoint = torch.load(ck_path)\n  model.load_state_dict(checkpoint['model_state_dict'])\n  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n  start_epoch = checkpoint['epoch']\n  start_step = checkpoint['step']\n  return model, optimizer, start_epoch, start_step","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T06:14:04.236862Z","iopub.execute_input":"2025-02-01T06:14:04.237152Z","iopub.status.idle":"2025-02-01T06:14:04.243398Z","shell.execute_reply.started":"2025-02-01T06:14:04.237132Z","shell.execute_reply":"2025-02-01T06:14:04.242686Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# Move the model to GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Optimizer\noptimizer = AdamW(model.parameters(), lr=5e-5)\n\n# Custom loss function (BCEWithLogitsLoss for multi-label classification)\nloss_fn = torch.nn.BCEWithLogitsLoss()\n\n# Function for calculating metrics\ndef compute_metrics(preds, labels):\n    sigmoid_preds = torch.sigmoid(preds).cpu().numpy()\n    sigmoid_preds = (sigmoid_preds > 0.5).astype(int)  # Convert logits to 0 or 1\n\n    labels = labels.cpu().numpy()\n    acc = accuracy_score(labels, sigmoid_preds)\n    f1 = f1_score(labels, sigmoid_preds, average='micro')\n\n    return {\"accuracy\": acc, \"f1\": f1}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T06:14:07.991899Z","iopub.execute_input":"2025-02-01T06:14:07.992195Z","iopub.status.idle":"2025-02-01T06:14:08.387683Z","shell.execute_reply.started":"2025-02-01T06:14:07.992175Z","shell.execute_reply":"2025-02-01T06:14:08.386898Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"from tqdm import tqdm\n\ndef train(model, optimizer, epochs=50, N = 100):\n  # Reload model and optimizer state from checkpoint\n  model, optimizer, start_epoch, start_step = load_checkpoint(model, optimizer, checkpoint_dir)\n\n  # Resume training from saved state\n  for epoch in range(start_epoch, epochs):\n      model.train()\n      for step, batch in tqdm(enumerate(train_dataloader, start=start_step), total=len(train_dataloader)):\n          optimizer.zero_grad()\n\n          # Move batch to the appropriate device\n          input_ids = batch['input_ids'].to(device)\n          attention_mask = batch['attention_mask'].to(device)\n          labels = batch['labels'].float().to(device)\n\n          # Forward pass\n          outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n          loss = outputs.loss\n\n          loss.backward()\n          optimizer.step()\n\n          # Continue saving checkpoints or additional logic as required\n          # Save checkpoint after every N steps\n          if step % N == 0:\n              save_checkpoint(model, optimizer, epoch, step)\n              # print(f\"Checkpoint saved at step {step} of epoch {epoch}.\")\n\n      print(f\"Epoch {epoch + 1}/{epochs} completed.\")\n      # Evaluate the model after each epoch\n      model.eval()\n      preds, true_labels = [], []\n      with torch.no_grad():\n          for batch in eval_dataloader:\n              input_ids = batch['input_ids'].to(device)\n              attention_mask = batch['attention_mask'].to(device)\n              labels = batch['labels'].float().to(device)\n\n              outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n              preds.append(outputs.logits)\n              true_labels.append(labels)\n\n      if epoch % 20 == 0:\n          model.push_to_hub(\"ollama-issues-classifier\")\n          tokenizer.push_to_hub(\"ollama-issues-classifier\")\n\n      preds = torch.cat(preds)\n      true_labels = torch.cat(true_labels)\n      metrics = compute_metrics(preds, true_labels)\n\n      print(f\"Validation metrics: {metrics}\")\n  model.push_to_hub(\"ollama-issues-classifier\")\n  tokenizer.push_to_hub(\"ollama-issues-classifier\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T06:57:10.17394Z","iopub.execute_input":"2025-02-01T06:57:10.174251Z","iopub.status.idle":"2025-02-01T06:57:10.182724Z","shell.execute_reply.started":"2025-02-01T06:57:10.174231Z","shell.execute_reply":"2025-02-01T06:57:10.181895Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"train(model, optimizer, epochs=50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T06:57:11.608744Z","iopub.execute_input":"2025-02-01T06:57:11.609085Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-26-f6dddbf6b9d7>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(ck_path)\n 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 412/561 [05:54<02:01,  1.22it/s]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}